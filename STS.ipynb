{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "STS.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snaiws/NLP_project/blob/RoBERTa%2Flarge/STS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Textual Similarity for Korean\n",
        "\n"
      ],
      "metadata": {
        "id": "3qfGz4Pa-Whu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "6R8hyvUu-1sK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sw7ilyV-KU8",
        "outputId": "ec17a727-1b7d-43d8-ce5b-4f41b49b59c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 14.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader,  RandomSampler, SequentialSampler, random_split\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AutoTokenizer\n"
      ],
      "metadata": {
        "id": "kpKhz3Xi_A2j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJA6wul9_SI3",
        "outputId": "57fa5336-ed29-4165-a79b-8419e967749d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla T4\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "3UzKrJFze4Le"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmKwlaCj_o-U",
        "outputId": "736a63e2-f758-44c2-d5f8-8282ae1d0b9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdAJVTDRcerk",
        "outputId": "364d2e82-1fdc-4de4-9ed7-e893a4557b7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/snaiws/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96O7yDjQ4GrO",
        "outputId": "19ab8153-4523-48bf-eb5a-d1bdcb51bec3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NLP_project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NLP_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3YRxEPN4H06",
        "outputId": "4d334d69-9d2e-411a-f180-8c286e0c01b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ARGUMENT and Model"
      ],
      "metadata": {
        "id": "Iz2aZrF5Wg6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/drive/MyDrive/NLP_project/CustomModels'))"
      ],
      "metadata": {
        "id": "0NoUvfiIbibP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d01e51-88e1-49ed-ccc2-e82468f6192b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BERT_baseline.py', 'BERT_seq.py', '__pycache__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class RoBERTa_large(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int, n_label: int, freeze_base: bool = False):\n",
        "        super(RoBERTa_large, self).__init__()\n",
        "\n",
        "        self.roberta = AutoModel.from_pretrained(\"klue/roberta-large\")\n",
        "\n",
        "        if freeze_base:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad=False\n",
        "\n",
        "        dropout_rate = 0.1\n",
        "        linear_layer_hidden_size = 6\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, linear_layer_hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(linear_layer_hidden_size, n_label)\n",
        "        )\n",
        "\n",
        "    \n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        last_hidden_states = outputs[0] # last hidden states (batch_size, sequence_len, hidden_size)\n",
        "        cls_token_last_hidden_states = last_hidden_states[:,0,:] # (batch_size, first_token, hidden_size)\n",
        "\n",
        "        logits = self.classifier(cls_token_last_hidden_states)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "C8ovoY6JAeHo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# argument setting\n",
        "train_batch_size = 20\n",
        "eval_batch_size = 64\n",
        "epochs=25\n",
        "patience=2\n",
        "\n",
        "loss_fct = nn.CrossEntropyLoss()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"klue/roberta-small\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"klue/roberta-base\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "customModel = RoBERTa_large(hidden_size=1024, n_label=6)\n",
        "customOptimizer = AdamW(\n",
        "    customModel.parameters(), # update 대상 파라미터를 입력\n",
        "    lr=2.335281794951567e-05,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "metadata": {
        "id": "CiEIKbbuWgTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49878b42-3cfa-4c6b-86ab-9e3023ac98e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Given data"
      ],
      "metadata": {
        "id": "yKpuYKgO_iBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 내 json 불러오기\n",
        "df_train0 = pd.read_json('./data/klue-sts-v1.1_train.json')\n",
        "df_test0 = pd.read_json('./data/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "XEnQbro_AFC3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape\n",
        "df_train0.shape, df_test0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4t-v3-EAdKr",
        "outputId": "7db00f05-7f5e-4fa9-fd19-c16d710c4a0a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11668, 6), (519, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collected data"
      ],
      "metadata": {
        "id": "OkjYey9KAmwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bhuXo-IiMf1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### target balence"
      ],
      "metadata": {
        "id": "mcNuklZsRJ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['labels'].map(lambda x: x['real-label']).hist(bins=50)"
      ],
      "metadata": {
        "id": "_oZuc4_sDF5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0['labels'].map(lambda x: x['binary-label']).value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "KQrM6E1I_9Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### duplicates"
      ],
      "metadata": {
        "id": "IHjeDztYBMBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 중복\n",
        "df_train0[df_train0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "id": "v7AhrCRiAi9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test0[df_test0.duplicated(['sentence1','sentence2'],keep=False)==True]"
      ],
      "metadata": {
        "id": "_yuCC-wKCnPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_train0.drop_duplicates(['sentence1','sentence2']),df_test0]).duplicated(['sentence1','sentence2']).sum()"
      ],
      "metadata": {
        "id": "SKhRexrZC4aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train0.isna().sum().sum()+df_test0.isna().sum().sum()"
      ],
      "metadata": {
        "id": "G0Y9-rovDxnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocess"
      ],
      "metadata": {
        "id": "ySxzpHXJQR1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "2L3Qg_QqFKpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_st(text):\n",
        "  text = re.sub(r\"[^ㄱ-힣0-9\\s]\",\"\",text)\n",
        "  return text\n",
        "\n",
        "def base_preprocess(train, test):\n",
        "    train = train.drop_duplicates(['sentence1','sentence2']).reset_index(drop=True)\n",
        "    s1 = train['sentence1'].map(lambda x: check_st(x))\n",
        "    s2 = train['sentence2'].map(lambda x: check_st(x))\n",
        "    real = train['labels'].map(lambda x: int(x['real-label']))\n",
        "    binary = train['labels'].map(lambda x: int(x['binary-label']))\n",
        "    train = pd.concat([s1,s2,real,binary],axis=1)\n",
        "    train.columns = ['sentence1','sentence2','real','binary']\n",
        "    train['sentence'] = train.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "    s1 = test['sentence1'].map(lambda x: check_st(x))\n",
        "    s2 = test['sentence2'].map(lambda x: check_st(x))\n",
        "    real = test['labels'].map(lambda x: int(x['real-label']))\n",
        "    binary = test['labels'].map(lambda x: int(x['binary-label']))\n",
        "    test = pd.concat([s1,s2,real,binary],axis=1)\n",
        "    test.columns = ['sentence1','sentence2','real','binary']\n",
        "    test['sentence'] = test.apply(lambda x: x['sentence1']+' [SEP] '+x['sentence2'],axis=1)\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "jVwblZvZQXGI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = base_preprocess(df_train0,df_test0)"
      ],
      "metadata": {
        "id": "u7hYDHWGCm0C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "fu8-BMqCC93p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation"
      ],
      "metadata": {
        "id": "IAIZB6y0kIyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nMHTC1mtkLKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token length"
      ],
      "metadata": {
        "id": "kzwHEv74DBou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tknz(text):\n",
        "    x = tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "            max_length=512,\n",
        "            return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "        )\n",
        "    return x"
      ],
      "metadata": {
        "id": "Sb9Ns_a6_w-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sentence1'].map(lambda x: tknz(x).input_ids.shape[1]).value_counts().sort_index().plot(kind='bar',figsize=(10,5))"
      ],
      "metadata": {
        "id": "mZHw4B4Ls3et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sentence2'].map(lambda x: tknz(x).input_ids.shape[1]).value_counts().sort_index().plot(kind='bar',figsize=(10,5))"
      ],
      "metadata": {
        "id": "qVQ_9azlPoBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sentence'].map(lambda x: tknz(x).input_ids.shape[1]).value_counts().sort_index().plot(kind='bar',figsize=(20,5))"
      ],
      "metadata": {
        "id": "Ss_2IIv8C09d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "DUsE3dGzTBpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - input_data: list of string\n",
        "    - target_data: list of int\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_data:list, target_data:list) -> None:\n",
        "        self.X = input_data\n",
        "        self.Y = target_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]"
      ],
      "metadata": {
        "id": "nrxcSuANS3ua"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(df_train.sentence.to_list(), df_train.real.to_list())\n",
        "test_dataset = CustomDataset(df_test.sentence.to_list(), df_test.real.to_list())"
      ],
      "metadata": {
        "id": "qHRSCsPX_XiU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "_xnq7qO8VeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_sample = df_train.shape[0] # train 전체 길이\n",
        "n_train = int(n_sample*0.9)\n",
        "n_valid = n_sample-n_train\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid],generator=torch.Generator().manual_seed(seed))"
      ],
      "metadata": {
        "id": "YhDSTrpoVhuM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid Dataset len: {len(valid_dataset)}\")\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3VF0hHy_qbg",
        "outputId": "581e53c6-3bd7-4af5-afa6-f962e69847d5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10494\n",
            "Valid Dataset len: 1167\n",
            "Test Dataset len: 519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plan"
      ],
      "metadata": {
        "id": "PUZIdwDiW8Wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "gxJnvrXwWENj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate_fn \n",
        "def BERT_base_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    한 배치 내 레이블(target)은 텐서화 함.\n",
        "    \n",
        "    - batch: list of tuples (input_data(string), target_data(int))\n",
        "    \"\"\"\n",
        "    input_list, target_list = [], []\n",
        "\n",
        "    for _input, _target in batch:\n",
        "        input_list.append(_input)\n",
        "        target_list.append(_target)\n",
        "    \n",
        "    tensorized_input = tokenizer(\n",
        "        input_list,\n",
        "        add_special_tokens=True,\n",
        "        padding=\"longest\", # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=512,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    tensorized_label = torch.tensor(target_list)\n",
        "    \n",
        "    return tensorized_input, tensorized_label"
      ],
      "metadata": {
        "id": "45DCZ7_5WGs4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_data_loader(train_dataset,valid_dataset,test_dataset):\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size = train_batch_size,\n",
        "        sampler = RandomSampler(train_dataset,generator=torch.Generator().manual_seed(seed)),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "    )\n",
        "\n",
        "    valid_dataloader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size = eval_batch_size,\n",
        "        sampler = SequentialSampler(valid_dataset),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "    )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size = eval_batch_size,\n",
        "        sampler = SequentialSampler(test_dataset),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "    )\n",
        "    print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "    print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "    print(f\"Test dataloader # steps: {len(test_dataloader)}\")\n",
        "    return train_dataloader, valid_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "afNNT7crFH28"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = init_data_loader(train_dataset,valid_dataset,test_dataset)"
      ],
      "metadata": {
        "id": "1hnqiWsHaiaW",
        "outputId": "e815c859-1e37-4a08-90e2-78a8455392a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 525\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializer"
      ],
      "metadata": {
        "id": "fb4K-Oo8Fc7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(model, optimizer, train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러 초기화\n",
        "    \"\"\"\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0, # 여기서는 warmup을 사용하지 않는다.\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "i4omKhdSQfpJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early stopping"
      ],
      "metadata": {
        "id": "NwgtRhD4FhSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=1, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = os.path.abspath(os.curdir)\n",
        "\n",
        "    def __call__(self, val_loss, model, optimizer, scheduler, epoch):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, optimizer, scheduler, epoch, val_loss)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, loss):\n",
        "        file_name = f'{self.path}/model.ckpt.best'\n",
        "        \n",
        "        torch.save(\n",
        "            {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'loss' : loss\n",
        "            }, \n",
        "            file_name\n",
        "        )\n",
        "      \n",
        "        print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ],
      "metadata": {
        "id": "xjTgaMgaJLIo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "X9A_WhPZIIW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, valid_dataloader=None, epochs=1):\n",
        "    # early_stopping object의 초기화\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "    \n",
        "    # train_dataloaer 학습을 epochs만큼 반복\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "        \n",
        "        # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "        total_loss, batch_loss, batch_count = 0,0,0\n",
        "    \n",
        "        # model을 train 모드로 설정 & device 할당\n",
        "        model.train()\n",
        "        model.to(device)\n",
        "        \n",
        "        # data iterator를 돌면서 하나씩 학습\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_count+=1\n",
        "            \n",
        "            # tensor 연산 전, 각 tensor에 device 할당\n",
        "            batch = tuple(item.to(device) for item in batch)\n",
        "        \n",
        "            batch_input, batch_label = batch\n",
        "        \n",
        "            # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "            model.zero_grad()\n",
        "        \n",
        "            # forward\n",
        "            logits = model(**batch_input)\n",
        "            # loss\n",
        "            loss = loss_fct(logits, batch_label)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "        \n",
        "            # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "            loss.backward()\n",
        "            \n",
        "            # gradient clipping 적용 \n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            # optimizer & scheduler 업데이트\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "            if (step % 10 == 0 and step != 0):\n",
        "                learning_rate = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                # reset \n",
        "                batch_loss, batch_count = 0,0\n",
        "        \n",
        "        print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "        print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "        \n",
        "        if valid_dataloader is not None:\n",
        "            print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "            valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "            print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "            print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "\n",
        "        # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
        "        #  만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
        "        early_stopping(valid_loss, model, optimizer, scheduler, epoch)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "            \n",
        "            \n",
        "    print(\"Train Completed. End Program.\")"
      ],
      "metadata": {
        "id": "kK09khnhJQfo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate"
      ],
      "metadata": {
        "id": "fBx_gbpYFmSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valid_dataloader):\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    total_loss, total_acc= 0,0\n",
        "        \n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않음\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "    \n",
        "    total_loss = total_loss/(step+1)\n",
        "    total_acc = total_acc/(step+1)*100\n",
        "\n",
        "    return total_loss, total_acc\n",
        "    "
      ],
      "metadata": {
        "id": "C21fot6EJNSL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "XuwLP7lzepZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZepTYxNV_QPi"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "y, M, d, h, m, s, w, yd, isdst = time.gmtime()\n",
        "current_time = f'{y}.{M}.{d} {h+9}:{m}:{s}'\n",
        "print(current_time)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "train_dataloader, valid_dataloader, test_dataloader = init_data_loader(train_dataset,valid_dataset,test_dataset)\n",
        "model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)\n",
        "train_model(model, train_dataloader, valid_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4QLtohXGJUJF",
        "outputId": "22a932ba-d2e3-4632-d24c-29cf36dd9af5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022.6.1 22:29:0\n",
            "Train dataloader # steps: 525\n",
            "Valid dataloader # steps: 19\n",
            "Test dataloader # steps: 9\n",
            "Total train steps with 25 epochs: 13125\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 10, LR : 2.3333246063996078e-05, Avg Loss : 1.6692\n",
            "Epoch: 1, Step : 20, LR : 2.3315453440796446e-05, Avg Loss : 1.5829\n",
            "Epoch: 1, Step : 30, LR : 2.3297660817596814e-05, Avg Loss : 1.2966\n",
            "Epoch: 1, Step : 40, LR : 2.3279868194397185e-05, Avg Loss : 1.1838\n",
            "Epoch: 1, Step : 50, LR : 2.3262075571197553e-05, Avg Loss : 1.1550\n",
            "Epoch: 1, Step : 60, LR : 2.3244282947997924e-05, Avg Loss : 0.9939\n",
            "Epoch: 1, Step : 70, LR : 2.3226490324798288e-05, Avg Loss : 1.1784\n",
            "Epoch: 1, Step : 80, LR : 2.320869770159866e-05, Avg Loss : 1.1007\n",
            "Epoch: 1, Step : 90, LR : 2.3190905078399027e-05, Avg Loss : 1.1100\n",
            "Epoch: 1, Step : 100, LR : 2.31731124551994e-05, Avg Loss : 1.1719\n",
            "Epoch: 1, Step : 110, LR : 2.3155319831999766e-05, Avg Loss : 1.1188\n",
            "Epoch: 1, Step : 120, LR : 2.3137527208800137e-05, Avg Loss : 1.1511\n",
            "Epoch: 1, Step : 130, LR : 2.3119734585600505e-05, Avg Loss : 1.1948\n",
            "Epoch: 1, Step : 140, LR : 2.3101941962400873e-05, Avg Loss : 1.1487\n",
            "Epoch: 1, Step : 150, LR : 2.3084149339201244e-05, Avg Loss : 1.0577\n",
            "Epoch: 1, Step : 160, LR : 2.3066356716001612e-05, Avg Loss : 1.0800\n",
            "Epoch: 1, Step : 170, LR : 2.3048564092801983e-05, Avg Loss : 0.9778\n",
            "Epoch: 1, Step : 180, LR : 2.3030771469602348e-05, Avg Loss : 1.1069\n",
            "Epoch: 1, Step : 190, LR : 2.301297884640272e-05, Avg Loss : 1.0131\n",
            "Epoch: 1, Step : 200, LR : 2.2995186223203086e-05, Avg Loss : 1.0323\n",
            "Epoch: 1, Step : 210, LR : 2.2977393600003458e-05, Avg Loss : 0.9619\n",
            "Epoch: 1, Step : 220, LR : 2.2959600976803825e-05, Avg Loss : 0.9361\n",
            "Epoch: 1, Step : 230, LR : 2.2941808353604197e-05, Avg Loss : 1.0053\n",
            "Epoch: 1, Step : 240, LR : 2.2924015730404564e-05, Avg Loss : 1.0274\n",
            "Epoch: 1, Step : 250, LR : 2.2906223107204932e-05, Avg Loss : 1.1380\n",
            "Epoch: 1, Step : 260, LR : 2.2888430484005303e-05, Avg Loss : 1.0599\n",
            "Epoch: 1, Step : 270, LR : 2.287063786080567e-05, Avg Loss : 1.0819\n",
            "Epoch: 1, Step : 280, LR : 2.2852845237606042e-05, Avg Loss : 1.0523\n",
            "Epoch: 1, Step : 290, LR : 2.2835052614406407e-05, Avg Loss : 0.9900\n",
            "Epoch: 1, Step : 300, LR : 2.2817259991206778e-05, Avg Loss : 0.9700\n",
            "Epoch: 1, Step : 310, LR : 2.2799467368007146e-05, Avg Loss : 1.0940\n",
            "Epoch: 1, Step : 320, LR : 2.2781674744807517e-05, Avg Loss : 1.0648\n",
            "Epoch: 1, Step : 330, LR : 2.2763882121607885e-05, Avg Loss : 1.0640\n",
            "Epoch: 1, Step : 340, LR : 2.2746089498408256e-05, Avg Loss : 0.9799\n",
            "Epoch: 1, Step : 350, LR : 2.2728296875208624e-05, Avg Loss : 0.9772\n",
            "Epoch: 1, Step : 360, LR : 2.271050425200899e-05, Avg Loss : 0.9279\n",
            "Epoch: 1, Step : 370, LR : 2.2692711628809363e-05, Avg Loss : 0.9517\n",
            "Epoch: 1, Step : 380, LR : 2.267491900560973e-05, Avg Loss : 1.0188\n",
            "Epoch: 1, Step : 390, LR : 2.26571263824101e-05, Avg Loss : 0.9395\n",
            "Epoch: 1, Step : 400, LR : 2.2639333759210466e-05, Avg Loss : 1.0959\n",
            "Epoch: 1, Step : 410, LR : 2.2621541136010837e-05, Avg Loss : 0.9383\n",
            "Epoch: 1, Step : 420, LR : 2.2603748512811205e-05, Avg Loss : 1.0308\n",
            "Epoch: 1, Step : 430, LR : 2.2585955889611576e-05, Avg Loss : 0.9267\n",
            "Epoch: 1, Step : 440, LR : 2.2568163266411944e-05, Avg Loss : 0.9569\n",
            "Epoch: 1, Step : 450, LR : 2.2550370643212312e-05, Avg Loss : 0.9401\n",
            "Epoch: 1, Step : 460, LR : 2.2532578020012683e-05, Avg Loss : 1.0319\n",
            "Epoch: 1, Step : 470, LR : 2.251478539681305e-05, Avg Loss : 0.9032\n",
            "Epoch: 1, Step : 480, LR : 2.2496992773613422e-05, Avg Loss : 1.0248\n",
            "Epoch: 1, Step : 490, LR : 2.247920015041379e-05, Avg Loss : 0.9249\n",
            "Epoch: 1, Step : 500, LR : 2.246140752721416e-05, Avg Loss : 0.9641\n",
            "Epoch: 1, Step : 510, LR : 2.2443614904014525e-05, Avg Loss : 0.9393\n",
            "Epoch: 1, Step : 520, LR : 2.2425822280814897e-05, Avg Loss : 1.0093\n",
            "Epoch 1 Total Mean Loss : 1.0635\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 0.8142 Valid Acc : 71.93\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "Saving epoch 1 checkpoint at /content/drive/MyDrive/NLP_project/model.ckpt.best\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 2.239913334601545e-05, Avg Loss : 0.8252\n",
            "Epoch: 2, Step : 20, LR : 2.238134072281582e-05, Avg Loss : 0.9032\n",
            "Epoch: 2, Step : 30, LR : 2.236354809961619e-05, Avg Loss : 0.8106\n",
            "Epoch: 2, Step : 40, LR : 2.2345755476416557e-05, Avg Loss : 0.9299\n",
            "Epoch: 2, Step : 50, LR : 2.2327962853216924e-05, Avg Loss : 0.8300\n",
            "Epoch: 2, Step : 60, LR : 2.2310170230017296e-05, Avg Loss : 0.9660\n",
            "Epoch: 2, Step : 70, LR : 2.2292377606817663e-05, Avg Loss : 0.9309\n",
            "Epoch: 2, Step : 80, LR : 2.2274584983618035e-05, Avg Loss : 0.9177\n",
            "Epoch: 2, Step : 90, LR : 2.2256792360418402e-05, Avg Loss : 0.9148\n",
            "Epoch: 2, Step : 100, LR : 2.223899973721877e-05, Avg Loss : 0.9178\n",
            "Epoch: 2, Step : 110, LR : 2.222120711401914e-05, Avg Loss : 0.9784\n",
            "Epoch: 2, Step : 120, LR : 2.220341449081951e-05, Avg Loss : 0.9110\n",
            "Epoch: 2, Step : 130, LR : 2.218562186761988e-05, Avg Loss : 0.8420\n",
            "Epoch: 2, Step : 140, LR : 2.2167829244420248e-05, Avg Loss : 0.8012\n",
            "Epoch: 2, Step : 150, LR : 2.2150036621220616e-05, Avg Loss : 0.8790\n",
            "Epoch: 2, Step : 160, LR : 2.2132243998020984e-05, Avg Loss : 0.8257\n",
            "Epoch: 2, Step : 170, LR : 2.2114451374821355e-05, Avg Loss : 0.8845\n",
            "Epoch: 2, Step : 180, LR : 2.2096658751621723e-05, Avg Loss : 0.8411\n",
            "Epoch: 2, Step : 190, LR : 2.2078866128422094e-05, Avg Loss : 0.7989\n",
            "Epoch: 2, Step : 200, LR : 2.206107350522246e-05, Avg Loss : 0.7499\n",
            "Epoch: 2, Step : 210, LR : 2.204328088202283e-05, Avg Loss : 0.7700\n",
            "Epoch: 2, Step : 220, LR : 2.20254882588232e-05, Avg Loss : 0.7449\n",
            "Epoch: 2, Step : 230, LR : 2.200769563562357e-05, Avg Loss : 1.0211\n",
            "Epoch: 2, Step : 240, LR : 2.198990301242394e-05, Avg Loss : 0.8409\n",
            "Epoch: 2, Step : 250, LR : 2.1972110389224304e-05, Avg Loss : 0.7873\n",
            "Epoch: 2, Step : 260, LR : 2.1954317766024675e-05, Avg Loss : 0.8201\n",
            "Epoch: 2, Step : 270, LR : 2.1936525142825043e-05, Avg Loss : 0.8300\n",
            "Epoch: 2, Step : 280, LR : 2.1918732519625414e-05, Avg Loss : 0.8760\n",
            "Epoch: 2, Step : 290, LR : 2.1900939896425782e-05, Avg Loss : 0.8843\n",
            "Epoch: 2, Step : 300, LR : 2.1883147273226153e-05, Avg Loss : 0.8433\n",
            "Epoch: 2, Step : 310, LR : 2.186535465002652e-05, Avg Loss : 0.9423\n",
            "Epoch: 2, Step : 320, LR : 2.184756202682689e-05, Avg Loss : 0.8249\n",
            "Epoch: 2, Step : 330, LR : 2.182976940362726e-05, Avg Loss : 0.8094\n",
            "Epoch: 2, Step : 340, LR : 2.1811976780427628e-05, Avg Loss : 0.9682\n",
            "Epoch: 2, Step : 350, LR : 2.1794184157228e-05, Avg Loss : 0.7552\n",
            "Epoch: 2, Step : 360, LR : 2.1776391534028363e-05, Avg Loss : 0.8163\n",
            "Epoch: 2, Step : 370, LR : 2.1758598910828734e-05, Avg Loss : 0.9389\n",
            "Epoch: 2, Step : 380, LR : 2.1740806287629102e-05, Avg Loss : 0.8702\n",
            "Epoch: 2, Step : 390, LR : 2.1723013664429473e-05, Avg Loss : 0.7925\n",
            "Epoch: 2, Step : 400, LR : 2.170522104122984e-05, Avg Loss : 0.8740\n",
            "Epoch: 2, Step : 410, LR : 2.1687428418030212e-05, Avg Loss : 0.7286\n",
            "Epoch: 2, Step : 420, LR : 2.166963579483058e-05, Avg Loss : 0.7753\n",
            "Epoch: 2, Step : 430, LR : 2.1651843171630948e-05, Avg Loss : 0.7781\n",
            "Epoch: 2, Step : 440, LR : 2.163405054843132e-05, Avg Loss : 0.8400\n",
            "Epoch: 2, Step : 450, LR : 2.1616257925231687e-05, Avg Loss : 0.8962\n",
            "Epoch: 2, Step : 460, LR : 2.1598465302032058e-05, Avg Loss : 0.7239\n",
            "Epoch: 2, Step : 470, LR : 2.1580672678832423e-05, Avg Loss : 0.8710\n",
            "Epoch: 2, Step : 480, LR : 2.1562880055632794e-05, Avg Loss : 0.8891\n",
            "Epoch: 2, Step : 490, LR : 2.154508743243316e-05, Avg Loss : 1.0309\n",
            "Epoch: 2, Step : 500, LR : 2.1527294809233533e-05, Avg Loss : 0.7478\n",
            "Epoch: 2, Step : 510, LR : 2.15095021860339e-05, Avg Loss : 0.8542\n",
            "Epoch: 2, Step : 520, LR : 2.1491709562834272e-05, Avg Loss : 0.9936\n",
            "Epoch 2 Total Mean Loss : 0.8550\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 0.8529 Valid Acc : 66.09\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "EarlyStopping counter: 1 out of 2\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 2.1465020628034822e-05, Avg Loss : 0.8390\n",
            "Epoch: 3, Step : 20, LR : 2.1447228004835193e-05, Avg Loss : 0.7400\n",
            "Epoch: 3, Step : 30, LR : 2.142943538163556e-05, Avg Loss : 0.7034\n",
            "Epoch: 3, Step : 40, LR : 2.1411642758435932e-05, Avg Loss : 0.7286\n",
            "Epoch: 3, Step : 50, LR : 2.13938501352363e-05, Avg Loss : 0.6232\n",
            "Epoch: 3, Step : 60, LR : 2.1376057512036667e-05, Avg Loss : 0.9048\n",
            "Epoch: 3, Step : 70, LR : 2.135826488883704e-05, Avg Loss : 0.6931\n",
            "Epoch: 3, Step : 80, LR : 2.1340472265637406e-05, Avg Loss : 0.7396\n",
            "Epoch: 3, Step : 90, LR : 2.1322679642437778e-05, Avg Loss : 0.7260\n",
            "Epoch: 3, Step : 100, LR : 2.1304887019238145e-05, Avg Loss : 0.8930\n",
            "Epoch: 3, Step : 110, LR : 2.1287094396038513e-05, Avg Loss : 0.7588\n",
            "Epoch: 3, Step : 120, LR : 2.126930177283888e-05, Avg Loss : 0.8706\n",
            "Epoch: 3, Step : 130, LR : 2.1251509149639252e-05, Avg Loss : 0.6886\n",
            "Epoch: 3, Step : 140, LR : 2.123371652643962e-05, Avg Loss : 0.8270\n",
            "Epoch: 3, Step : 150, LR : 2.121592390323999e-05, Avg Loss : 0.7116\n",
            "Epoch: 3, Step : 160, LR : 2.119813128004036e-05, Avg Loss : 0.7381\n",
            "Epoch: 3, Step : 170, LR : 2.1180338656840727e-05, Avg Loss : 0.7104\n",
            "Epoch: 3, Step : 180, LR : 2.1162546033641098e-05, Avg Loss : 0.7843\n",
            "Epoch: 3, Step : 190, LR : 2.1144753410441466e-05, Avg Loss : 0.6674\n",
            "Epoch: 3, Step : 200, LR : 2.1126960787241837e-05, Avg Loss : 0.5769\n",
            "Epoch: 3, Step : 210, LR : 2.1109168164042205e-05, Avg Loss : 0.7501\n",
            "Epoch: 3, Step : 220, LR : 2.1091375540842572e-05, Avg Loss : 0.8292\n",
            "Epoch: 3, Step : 230, LR : 2.107358291764294e-05, Avg Loss : 0.6746\n",
            "Epoch: 3, Step : 240, LR : 2.105579029444331e-05, Avg Loss : 0.7664\n",
            "Epoch: 3, Step : 250, LR : 2.103799767124368e-05, Avg Loss : 0.7512\n",
            "Epoch: 3, Step : 260, LR : 2.102020504804405e-05, Avg Loss : 0.6878\n",
            "Epoch: 3, Step : 270, LR : 2.1002412424844418e-05, Avg Loss : 0.7759\n",
            "Epoch: 3, Step : 280, LR : 2.0984619801644786e-05, Avg Loss : 0.6693\n",
            "Epoch: 3, Step : 290, LR : 2.0966827178445157e-05, Avg Loss : 0.7369\n",
            "Epoch: 3, Step : 300, LR : 2.0949034555245525e-05, Avg Loss : 0.8383\n",
            "Epoch: 3, Step : 310, LR : 2.0931241932045896e-05, Avg Loss : 0.6789\n",
            "Epoch: 3, Step : 320, LR : 2.0913449308846264e-05, Avg Loss : 0.7473\n",
            "Epoch: 3, Step : 330, LR : 2.0895656685646632e-05, Avg Loss : 0.7024\n",
            "Epoch: 3, Step : 340, LR : 2.0877864062447e-05, Avg Loss : 0.7723\n",
            "Epoch: 3, Step : 350, LR : 2.086007143924737e-05, Avg Loss : 0.7630\n",
            "Epoch: 3, Step : 360, LR : 2.084227881604774e-05, Avg Loss : 0.7486\n",
            "Epoch: 3, Step : 370, LR : 2.082448619284811e-05, Avg Loss : 0.6560\n",
            "Epoch: 3, Step : 380, LR : 2.0806693569648474e-05, Avg Loss : 0.7189\n",
            "Epoch: 3, Step : 390, LR : 2.0788900946448845e-05, Avg Loss : 0.6730\n",
            "Epoch: 3, Step : 400, LR : 2.0771108323249216e-05, Avg Loss : 0.6783\n",
            "Epoch: 3, Step : 410, LR : 2.0753315700049584e-05, Avg Loss : 0.6413\n",
            "Epoch: 3, Step : 420, LR : 2.0735523076849955e-05, Avg Loss : 0.6820\n",
            "Epoch: 3, Step : 430, LR : 2.071773045365032e-05, Avg Loss : 0.6725\n",
            "Epoch: 3, Step : 440, LR : 2.069993783045069e-05, Avg Loss : 0.6608\n",
            "Epoch: 3, Step : 450, LR : 2.068214520725106e-05, Avg Loss : 0.6690\n",
            "Epoch: 3, Step : 460, LR : 2.066435258405143e-05, Avg Loss : 0.6915\n",
            "Epoch: 3, Step : 470, LR : 2.0646559960851798e-05, Avg Loss : 0.7803\n",
            "Epoch: 3, Step : 480, LR : 2.062876733765217e-05, Avg Loss : 0.7123\n",
            "Epoch: 3, Step : 490, LR : 2.0610974714452533e-05, Avg Loss : 0.7364\n",
            "Epoch: 3, Step : 500, LR : 2.0593182091252905e-05, Avg Loss : 0.6405\n",
            "Epoch: 3, Step : 510, LR : 2.0575389468053272e-05, Avg Loss : 0.6785\n",
            "Epoch: 3, Step : 520, LR : 2.0557596844853644e-05, Avg Loss : 0.6255\n",
            "Epoch 3 Total Mean Loss : 0.7253\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 0.7362 Valid Acc : 75.02\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "Saving epoch 3 checkpoint at /content/drive/MyDrive/NLP_project/model.ckpt.best\n",
            "*****Epoch 4 Train Start*****\n",
            "Epoch: 4, Step : 10, LR : 2.0530907910054197e-05, Avg Loss : 0.6645\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d7b4a9fe16d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustomOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-5abf40c99495>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, valid_dataloader, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# gradient clipping 적용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# optimizer & scheduler 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0m_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# noqa: C416 TODO: rewrite as list(range(m))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m     \u001b[0;31m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "GFiQGULKrxfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load checkpoint"
      ],
      "metadata": {
        "id": "4aim45otF4si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(f'./model.ckpt.best')"
      ],
      "metadata": {
        "id": "I4StQ5rCRPJt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSy2twvbRSHd",
        "outputId": "cf93787b-cdee-43bc-fc90-a18f10b76dba"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(customModel, customOptimizer, train_dataloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOuSODA6RSQ9",
        "outputId": "a114dc45-a6e7-49fa-9e3d-e75fde520db2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 1 epochs: 525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAoxlaI_RSTb",
        "outputId": "4ca060ce-d3d7-4756-ca4e-e52ad3673be4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict and evaluate"
      ],
      "metadata": {
        "id": "w1uKfufLF8kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        print(f\"{step}/{len(test_dataloader)}\")\n",
        "        \n",
        "        batch_input, batch_label = batch\n",
        "        \n",
        "        batch_input = batch_input.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            all_logits.append(logits)\n",
        "        all_labels.extend(batch_label)\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return probs, all_labels\n"
      ],
      "metadata": {
        "id": "UhtXfy8kJvMR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "NQAuNkxRRdxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06286dec-b7b5-476d-f9a8-d81e60968af2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))"
      ],
      "metadata": {
        "id": "MjSIuizoaVg1"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from scipy.stats import pearsonr\n",
        "def evaluate(pred, test):\n",
        "    if len(set(pred))==2:\n",
        "        pred_binary = pred\n",
        "        test_binary_label = test\n",
        "    else:\n",
        "        pred_binary = list(map(lambda x: 1 if x>=3 else 0, pred))\n",
        "        test_binary_label = list(map(lambda x: 1 if x>=3 else 0, test))\n",
        "    print(f'acc : {accuracy_score(test_binary_label, pred_binary)}')\n",
        "    print(f'f1 : {f1_score(test_binary_label, pred_binary)}')\n",
        "    print(f'pearson : {pearsonr(test, pred)}')\n",
        "    return f1_score(test_binary_label, pred_binary)\n",
        "    "
      ],
      "metadata": {
        "id": "r_CM_p_SzS3t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv_HfFaARi6o",
        "outputId": "39ea3b86-169c-4c33-f83a-7ca438c785ea"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.8169556840077071\n",
            "f1 : 0.8197343453510436\n",
            "pearson : (0.8532410401789287, 2.762453970921971e-148)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8197343453510436"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save outputs"
      ],
      "metadata": {
        "id": "UwfT52-LGDrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame(labels,columns=['pred_real_label'])\n",
        "filename = input()\n",
        "output.to_csv(f'{filename}.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWOiLVeOGFay",
        "outputId": "2b8a02fb-6c85-4b9e-a165-66c01fce97a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT_seq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "G7e_OlKR4qni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model weights"
      ],
      "metadata": {
        "id": "ODz2YVO45-MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Bert_baseline(hidden_size=768, n_label=6)"
      ],
      "metadata": {
        "id": "nNiDZphx5FXK",
        "outputId": "0ee120c1-cc92-4a8d-ce9b-4f7772b7bb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()\n",
        "probs, labels = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "rG_D-WBV5kMU",
        "outputId": "4effe6e2-a9ea-46d8-ecf4-c442a3939ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/9\n",
            "1/9\n",
            "2/9\n",
            "3/9\n",
            "4/9\n",
            "5/9\n",
            "6/9\n",
            "7/9\n",
            "8/9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = list(map(np.argmax,probs))\n",
        "evaluate(pred, labels)"
      ],
      "metadata": {
        "id": "vzg0kIpZ5z66",
        "outputId": "4961f688-3c8b-4f89-94fc-ac026e7fe063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.7533718689788054\n",
            "f1 : 0.7697841726618705\n",
            "pearson : (0.7789983354145806, 7.071859924703616e-107)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ],
      "metadata": {
        "id": "ZDS8IJNaVyB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "C91sdB_P6Cym",
        "outputId": "20247f98-4477-4b7d-df10-6fdfdc567d97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 84.3 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 70.9 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=8f4f1ccf98f0bd347a9426e3321de26f38fe8ef493725a8b687cea320cc39114\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "YrDmE0uyMjvu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optuna_train(model, optimizer):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "        batch_input, batch_label = batch\n",
        "        model.zero_grad()\n",
        "        logits = model(**batch_input)\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "QJT780IPACjs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):  # `trial` is an object passed by Optuna.\n",
        "    lr = trial.suggest_float(\"lr\",1e-6,1e-3,log=True)\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size = train_batch_size,\n",
        "        sampler = RandomSampler(train_dataset),\n",
        "        collate_fn = BERT_base_collate_fn\n",
        "        )\n",
        "    model = customModel\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr = lr\n",
        "        )\n",
        "    val_list = []\n",
        "    for epoch in range(4):\n",
        "        optuna_train(model,optimizer)\n",
        "        valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "        print(f'val_los : {valid_loss}')\n",
        "        trial.report(valid_loss, step = epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "        val_list.append(valid_loss)\n",
        "    return min(val_list)"
      ],
      "metadata": {
        "id": "jksNuvvL6C03"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reset gpu cache\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "v_L_9OT9mivx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=seed),\n",
        "    pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, \n",
        "        max_resource=4, \n",
        "        reduction_factor=3\n",
        "    ))\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "KuKNaaDS6C56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "cec67d88-3c4b-44ce-d6d7-f8fc17ae1b73"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-01 13:58:25,074]\u001b[0m A new study created in memory with name: no-name-9829399e-27b8-4b41-967e-623bad664e3d\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-11310bf31e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mreduction_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     ))\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-3b51a1403404>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moptuna_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'val_los : {valid_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-b942e528c784>\u001b[0m in \u001b[0;36moptuna_train\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Minimum objective value: ' + str(study.best_value))\n",
        "print('Best parameter: ' + str(study.best_params))"
      ],
      "metadata": {
        "id": "QarUZ2Vm6C3c",
        "outputId": "b87790be-fd26-448b-f0c2-a81f18dc638a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-d33a5a21f9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minimum objective value: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameter: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mbest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mbest_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mbest_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
          ]
        }
      ]
    }
  ]
}